{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d76df3",
   "metadata": {},
   "source": [
    "# Final TCGA Model Training/Hyperparameter Opotimisation and validation against CGGA data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e465b",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f269952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from scipy.special import expit, logit\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, average_precision_score,\n",
    "                             roc_curve, precision_recall_curve, balanced_accuracy_score)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "from sksurv.util import Surv\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping, Callback\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from dcurves import dca, plot_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b98c7",
   "metadata": {},
   "source": [
    "### Defining ANN Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "### Defining Helper Classes for ANN ###\n",
    "#######################################\n",
    "\n",
    "# Focal Loss class for enabling training focused on the difficult to predict class\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=5, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        targets = targets.view(-1,1).type_as(logits)\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "# Class for the ANN model (binary classification)\n",
    "class DeepBinary(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, num_layers=4, dropout_rate=0.25):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.LazyLinear(hidden_dim))\n",
    "        layers.append(nn.LayerNorm(hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.LayerNorm(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_dim, 1))  # final logit\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Defining NeuralNet class which will be necessary for use with skorch and skopt\n",
    "class NeuralNetBinaryClassifier(NeuralNetClassifier):\n",
    "    def predict_proba(self, X):\n",
    "        logits = self.forward(X).detach().cpu().numpy()\n",
    "        probs = expit(logits)\n",
    "        return np.hstack((1 - probs, probs))\n",
    "\n",
    "############################################\n",
    "### Defining Deep Learning Skorch Set up ###\n",
    "############################################\n",
    "\n",
    "# Defining the base ANN model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    module = DeepBinary,\n",
    "    criterion = FocalLoss,\n",
    "    criterion__alpha = 0.25,\n",
    "    criterion__gamma = 2.0,\n",
    "    max_epochs = 500,\n",
    "    lr = 1e-3,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    optimizer__weight_decay=1e-4,\n",
    "    batch_size = 128,\n",
    "    device = device,\n",
    "    verbose = 0,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor='valid_loss',\n",
    "            threshold=0.01,\n",
    "            patience=100,\n",
    "            lower_is_better=True,\n",
    "            load_best=False\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b4b33",
   "metadata": {},
   "source": [
    "### Defining Hyperparameter Search Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19226d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the ANN search space\n",
    "deep_search_space = {\n",
    "    \"lr\": Real(0.000001, 0.01, prior=\"log-uniform\"),\n",
    "    \"module__hidden_dim\": Integer(4, 256),\n",
    "    \"module__num_layers\": Integer(1, 4),\n",
    "    \"module__dropout_rate\": Real(0.0, 0.5),\n",
    "    \"criterion__alpha\": Real(0.0, 0.5),\n",
    "    \"criterion__gamma\": Real(1.0, 7.0)\n",
    "}\n",
    "\n",
    "############################################\n",
    "### Defining non ANN model search spaces ###\n",
    "############################################\n",
    "\n",
    "search_spaces = {\n",
    "    \"SVM\": (\n",
    "        SVC(probability=True, class_weight=\"balanced\", kernel = 'rbf', gamma='scale', random_state=42),\n",
    "        {\n",
    "            \"C\": Real(0.001, 1.0, prior=\"log-uniform\")\n",
    "        }\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": Integer(50, 500),\n",
    "            \"max_depth\": Integer(2, 20),\n",
    "            \"min_samples_split\": Integer(2, 20),\n",
    "            \"min_samples_leaf\": Integer(1, 10),\n",
    "        }\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(eval_metric=\"logloss\", random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": Integer(50, 500),\n",
    "            \"max_depth\": Integer(2, 20),\n",
    "            \"learning_rate\": Real(0.001, 0.1, prior=\"log-uniform\"),\n",
    "            \"subsample\": Real(0.5, 1.0),\n",
    "            \"colsample_bytree\": Real(0.5, 1.0),\n",
    "            \"scale_pos_weight\": Real(1.0, 10.0)\n",
    "        }\n",
    "    ),\n",
    "    \"LogisticRegression\": (\n",
    "        LogisticRegression(max_iter=5000, class_weight=\"balanced\", solver=\"lbfgs\"),\n",
    "        {\n",
    "            \"C\": Real(0.001, 1.0, prior=\"log-uniform\")\n",
    "        }\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2226d076",
   "metadata": {},
   "source": [
    "### Defining utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4623e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### Defining Utility Functions ###\n",
    "##################################\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(y_true, probs, threshold=0.5):\n",
    "    y_pred = (probs >= threshold).astype(int)\n",
    "    return {'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'recall': recall_score(y_true, y_pred),\n",
    "            'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "            'roc_auc': roc_auc_score(y_true, probs),\n",
    "            'pr_auc': average_precision_score(y_true, probs)}\n",
    "\n",
    "# Alternative Function for tuning on log-rank z\n",
    "def tune_threshold_by_logrank(\n",
    "    probs_train: np.ndarray,\n",
    "    time_train: np.ndarray,\n",
    "    event_train: np.ndarray,\n",
    ") -> tuple[float, float]:\n",
    "    \n",
    "    probs_train = np.asarray(probs_train, float).ravel()\n",
    "    time_train  = np.asarray(time_train,  float).ravel()\n",
    "    event_train = np.asarray(event_train, bool).ravel()\n",
    "\n",
    "    # Candidate thresholds from fixed quantiles\n",
    "    qs = np.linspace(0.3, 0.7, 41)\n",
    "    cands = np.unique(np.quantile(probs_train, qs))\n",
    "    best_thr  = float(np.median(probs_train))\n",
    "    best_stat = -np.inf\n",
    "    found     = False\n",
    "\n",
    "    for thr in cands:\n",
    "        hi = probs_train >= thr\n",
    "        lo = ~hi\n",
    "        if hi.sum() == 0 or lo.sum() == 0:\n",
    "            continue\n",
    "        try:\n",
    "            lr = logrank_test(\n",
    "                time_train[hi], time_train[lo],\n",
    "                event_observed_A=event_train[hi],\n",
    "                event_observed_B=event_train[lo],\n",
    "            )\n",
    "            chi2 = float(lr.test_statistic)\n",
    "            if np.isfinite(chi2) and chi2 > best_stat:\n",
    "                best_stat = chi2\n",
    "                best_thr  = float(thr)\n",
    "                found     = True\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not found:\n",
    "        # fallback: median threshold, 0 separation\n",
    "        return float(np.median(probs_train)), 0.0\n",
    "\n",
    "    return best_thr, best_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a025bea",
   "metadata": {},
   "source": [
    "### Defining training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acec5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(random_state=42,inner_folds=3,inner_iterations=25,ANN_iterations=25):\n",
    "\n",
    "    # Stetting variables\n",
    "    RANDOM_STATE = random_state\n",
    "    INNER_FOLDS = inner_folds\n",
    "    N_ITER_INNER = inner_iterations\n",
    "    N_ITER_ANN = ANN_iterations\n",
    "    N_JOBS = -1\n",
    "\n",
    "    # Downloading TCGA Data (Training)\n",
    "    TCGA_URL = \"./iMAT_integrated_data/TCGA_iMAT_integrated_df_5.csv\"\n",
    "    TCGA = pd.read_csv(TCGA_URL).drop(columns=[\"sample\"])\n",
    "    TCGA = TCGA.dropna()\n",
    "    TCGA_OS = TCGA[[\"OS\", \"OS.time\"]]\n",
    "\n",
    "    le = LabelEncoder().fit(TCGA[\"OS\"])\n",
    "\n",
    "    X_TCGA = TCGA.drop(columns = [\"OS\", \"OS.time\"])\n",
    "    y_TCGA = le.transform(TCGA[\"OS\"])\n",
    "\n",
    "    # Downloading CGGA Data (Validation)\n",
    "    CGGA_URL = \"./CGGA_Data/CGGA_Tidied_Integrated.csv\"\n",
    "    CGGA = pd.read_csv(CGGA_URL)\n",
    "    CGGA = CGGA.dropna()\n",
    "    CGGA_IDs = CGGA['CGGA_ID'].values\n",
    "    CGGA = CGGA.drop(columns=[\"CGGA_ID\"])\n",
    "    CGGA_OS = CGGA[[\"OS\", \"OS.time\"]]\n",
    "\n",
    "    X_CGGA = CGGA.drop(columns = [\"OS\", \"OS.time\"])\n",
    "    y_CGGA = le.transform(CGGA[\"OS\"])\n",
    "\n",
    "    # Preparing storage dictionaries\n",
    "    models_info = {name: {'estimator': m, 'space': s} for name, (m, s) in search_spaces.items()}\n",
    "    models_info['ANN'] = {'estimator': net, 'space': deep_search_space}\n",
    "\n",
    "    # Setting up event and time datasets\n",
    "    TCGA_event = TCGA_OS['OS'].values.astype(bool)\n",
    "    TCGA_time  = TCGA_OS['OS.time'].values.astype(float)\n",
    "\n",
    "    CGGA_event  = CGGA_OS['OS'].values.astype(bool)\n",
    "    CGGA_time   = CGGA_OS['OS.time'].values.astype(float)\n",
    "\n",
    "    # Setting up results dataframes\n",
    "    probs_train_store = {}\n",
    "    probs_results = {'y_true':y_CGGA}\n",
    "    class_results = {'y_true':y_CGGA}\n",
    "    metrics_results = {}\n",
    "    roc_results = {}\n",
    "    pr_results = {}\n",
    "\n",
    "    for model_name, info in models_info.items():\n",
    "        print(f'\\nTuning and Fitting: {model_name}')\n",
    "        base = clone(info['estimator'])\n",
    "        space = info['space']\n",
    "\n",
    "        # Defining the pipeline for the model\n",
    "        pipe = Pipeline([\n",
    "            ('low_var', VarianceThreshold()),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('smote', SMOTE(random_state=RANDOM_STATE,sampling_strategy=0.5)),\n",
    "            ('clf', base)\n",
    "        ])\n",
    "\n",
    "\n",
    "        # prefix search space\n",
    "        space_prefixed = {f'clf__{k}': v for k, v in space.items()}\n",
    "\n",
    "\n",
    "        #Selecting iterations\n",
    "        n_iter = N_ITER_ANN if model_name == 'ANN' else N_ITER_INNER\n",
    "        n_jobs = 1 if model_name == 'ANN' else N_JOBS\n",
    "\n",
    "        opt=BayesSearchCV(\n",
    "            estimator=pipe,\n",
    "            search_spaces=space_prefixed,\n",
    "            n_iter=n_iter,\n",
    "            scoring='average_precision',\n",
    "            cv=INNER_FOLDS,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=n_jobs,\n",
    "            refit=True,\n",
    "            #optimizer_kwargs={'n_initial_points': 50}\n",
    "        )\n",
    "\n",
    "        # Fitting\n",
    "        fit_X = X_TCGA.astype(np.float32) if model_name == 'ANN' else X_TCGA\n",
    "        opt.fit(fit_X, y_TCGA)\n",
    "\n",
    "        # Plotting Loss Curves\n",
    "        if model_name == \"ANN\":\n",
    "            best = opt.best_estimator_\n",
    "            \n",
    "            # skorch Net is inside the pipeline as step 'clf'\n",
    "            net_trained = best.named_steps['clf']\n",
    "\n",
    "            # Access the training history\n",
    "            history = net_trained.history_\n",
    "\n",
    "            # Extract values\n",
    "            train_losses = history[:, 'train_loss']\n",
    "            valid_losses = history[:, 'valid_loss']\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot(train_losses, label=\"Train Loss\")\n",
    "            if valid_losses is not None:\n",
    "                plt.plot(valid_losses, label=\"Valid Loss\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(f\"ANN Loss Curve\")\n",
    "            plt.legend()\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"Best params for {model_name}: {opt.best_params_}\")\n",
    "\n",
    "        # In this case fit base estimator inside the pipeline without search\n",
    "        best = opt.best_estimator_\n",
    "\n",
    "        \n",
    "        # Tuning for best threshold:\n",
    "        train_preds_input = fit_X.astype(np.float32) if model_name == 'ANN' else fit_X\n",
    "        probs_train = best.predict_proba(train_preds_input)[:, 1].ravel()\n",
    "\n",
    "        # Store training probs\n",
    "        probs_train_store[model_name] = probs_train\n",
    "\n",
    "        # Tuning threshold on training data\n",
    "        thr, thr_best = tune_threshold_by_logrank(probs_train=probs_train, time_train=TCGA_time,event_train=TCGA_event)\n",
    "        print(f\"Tuned threshold for {model_name}: {thr:.2f} (Log-Rank Chi2={thr_best:.3f})\")\n",
    "\n",
    "        # Predict proba on the test set\n",
    "        test_X = X_CGGA.astype(np.float32) if model_name == 'ANN' else X_CGGA\n",
    "        probs = best.predict_proba(test_X)[:, 1].ravel()\n",
    "\n",
    "        # Storing testing probs\n",
    "        probs_results[model_name] = probs\n",
    "        \n",
    "        # Storing out of fold predictions\n",
    "        model_predictions = (probs >= thr).astype(int)\n",
    "        class_results[model_name] = model_predictions\n",
    "\n",
    "        # Compute per-fold metrics and curves\n",
    "        m = compute_metrics(y_CGGA, probs, threshold=thr)\n",
    "        metrics_results[model_name] = m\n",
    "        fpr, tpr, _ = roc_curve(y_CGGA, probs)\n",
    "        prec, rec, _ = precision_recall_curve(y_CGGA, probs)\n",
    "        roc_results[model_name] = (fpr, tpr)\n",
    "        pr_results[model_name] = (rec, prec)\n",
    "\n",
    "        print(f\"{model_name}: AP={m['pr_auc']:.3f}, ROC AUC={m['roc_auc']:.3f}\")\n",
    "\n",
    "    # Computing Ensemble predictions for this fold against the train set for threshold tuning\n",
    "    model_list = [\"SVM\",\"RandomForest\",\"XGBoost\",\"LogisticRegression\",\"ANN\"]\n",
    "    L_train = np.vstack([probs_train_store[m]for m in model_list]).T\n",
    "    std_scaler = StandardScaler().fit(L_train)\n",
    "    Z_train = std_scaler.transform(L_train)\n",
    "\n",
    "    probs_train_df = pd.DataFrame(Z_train, columns=model_list)\n",
    "    probs_train_df[\"OS\"] = TCGA_event\n",
    "    probs_train_df[\"OS.time\"] = TCGA_time\n",
    "\n",
    "    cph = CoxPHFitter(penalizer=0.05, l1_ratio=0.0)\n",
    "    cph.fit(probs_train_df, duration_col=\"OS.time\", event_col=\"OS\", robust=True)\n",
    "\n",
    "    beta_vec = cph.params_[model_list].values\n",
    "    eta_train = Z_train @ beta_vec               \n",
    "\n",
    "    # Threshold tuning on TRAIN\n",
    "    thr_ens, thr_ens_best = tune_threshold_by_logrank(eta_train, TCGA_time, TCGA_event)\n",
    "\n",
    "    probs_train_store['Ensemble'] = eta_train\n",
    "    print(f\"Tuned threshold for Ensemble: {thr_ens:.2f} (Log-Rank Chi2={thr_ens_best:.3f})\")\n",
    "\n",
    "    # Computing Ensemble predictions for this fold against the test set\n",
    "    L_test = np.vstack([probs_results[m] for m in model_list]).T\n",
    "    Z_test = std_scaler.transform(L_test)\n",
    "    eta_test = Z_test @ beta_vec\n",
    "\n",
    "    probs_results['Ensemble'] = eta_test\n",
    "\n",
    "    #Calculating ensemble predictions\n",
    "    ensemble_preds = (eta_test >= thr_ens).astype(int)\n",
    "    class_results['Ensemble'] = ensemble_preds\n",
    "\n",
    "    # Store ensemble metrics and curves\n",
    "    m_ens = compute_metrics(y_CGGA, eta_test, threshold=thr_ens)\n",
    "    metrics_results['Ensemble'] = (m_ens)\n",
    "    fpr, tpr, _ = roc_curve(y_CGGA, eta_test)\n",
    "    prec, rec, _ = precision_recall_curve(y_CGGA, eta_test)\n",
    "    roc_results['Ensemble'] = (fpr, tpr)\n",
    "    pr_results['Ensemble'] = (rec, prec)\n",
    "    \n",
    "    probs_df = pd.DataFrame(probs_results)\n",
    "    class_df = pd.DataFrame(class_results)\n",
    "\n",
    "    model_list = [\"SVM\",\"RandomForest\",\"XGBoost\",\"LogisticRegression\",\"ANN\",\"Ensemble\"]\n",
    "\n",
    "    summary_df = pd.DataFrame({\n",
    "        'CGGA_ID': CGGA_IDs,\n",
    "        'y_true': y_CGGA,\n",
    "        'OS.time': CGGA_time,\n",
    "        'OS': CGGA_event.astype(int)\n",
    "    })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_results).T\n",
    "    for m in model_list:\n",
    "        summary_df[f'prob_{m}'] = probs_results[m]\n",
    "        summary_df[f'pred_{m}'] = class_results[m]\n",
    "    \n",
    "    curves_summary = {'roc': {}, 'pr': {}}\n",
    "    for m in model_list:\n",
    "        fpr, tpr, _ = roc_curve(probs_df['y_true'], probs_df[m])\n",
    "        prec, rec, _ = precision_recall_curve(probs_df['y_true'], probs_df[m])\n",
    "        curves_summary['roc'][m] = fpr, tpr\n",
    "        curves_summary['pr'][m]  = rec, prec\n",
    "\n",
    "    # Preparing survival resutls dictionaries\n",
    "    survival_results = {}\n",
    "    for m in [\"SVM\",\"RandomForest\",\"XGBoost\",\"LogisticRegression\",\"ANN\"]:\n",
    "        p = np.clip(probs_results[m], 1e-6, 1-1e-6)\n",
    "        zlogit = zscore(logit(p))      \n",
    "        survival_results[m] = [(pd.DataFrame({\"OS.time\": CGGA_time, \"OS\": CGGA_event}),\n",
    "                                {\"class\": class_results[m].astype(int),\n",
    "                                \"score\": zlogit})]\n",
    "    \n",
    "    survival_results[\"Ensemble\"] = [(pd.DataFrame({\"OS.time\": CGGA_time, \"OS\": CGGA_event}),\n",
    "                                 {\"class\": class_results[\"Ensemble\"].astype(int),\n",
    "                                  \"score\": eta_test})]\n",
    "\n",
    "    return summary_df, curves_summary, metrics_results, metrics_df, survival_results, y_CGGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df, curves_summary, metrics_results, metrics_df, survival_results, y_CGGA = train_evaluate_model(random_state=24,inner_folds=3,inner_iterations=5,ANN_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot mean ROC curves\n",
    "def plot_mean_roc(curves_summary):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for model_name, (fpr, mean_tpr) in curves_summary['roc'].items():\n",
    "        plt.plot(fpr, mean_tpr, label=f'{model_name}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.title(\"CV Pooled ROC-Curves\", fontsize=18)\n",
    "    plt.tick_params(axis=\"both\", labelsize=14)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Function to plot mean PR curves\n",
    "def plot_mean_pr(curves_summary):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for model_name, (recall, mean_prec) in curves_summary['pr'].items():\n",
    "        plt.plot(recall, mean_prec, label=f'{model_name}')\n",
    "    plt.hlines(y_CGGA.sum()/len(y_CGGA), 0, 1, colors=\"k\", linestyles=\"--\", label=\"Baseline\")\n",
    "    plt.xlabel('Recall', fontsize=16)\n",
    "    plt.ylabel('Precision', fontsize=16)\n",
    "    plt.title(\"CV Pooled PR-Curves\", fontsize=18)\n",
    "    plt.tick_params(axis=\"both\", labelsize=14)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_mean_roc(curves_summary)\n",
    "plot_mean_pr(curves_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_km_curves(survival_results, max_years=5):\n",
    "    risk_labels = {0: \"Low Risk\", 1: \"High Risk\"}\n",
    "    model_list = list(survival_results.keys())\n",
    "    colours = [\"#C190F0\", \"#35AB6A\"]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    logrank_ps = []\n",
    "    iteration = 0\n",
    "    for idx, model_name in enumerate(model_list):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        # Pool all folds\n",
    "        dfs = []\n",
    "        for OS_val, pred_dict in survival_results[model_name]:\n",
    "            temp = OS_val.copy()\n",
    "            temp[\"pred_class\"] = pred_dict[\"class\"]\n",
    "            dfs.append(temp)\n",
    "        pooled_df = pd.concat(dfs, ignore_index=True).dropna()\n",
    "\n",
    "        high = pooled_df[pooled_df[\"pred_class\"] == 1]\n",
    "        low  = pooled_df[pooled_df[\"pred_class\"] == 0]\n",
    "        lr_res = logrank_test(\n",
    "            high[\"OS.time\"], low[\"OS.time\"],\n",
    "            event_observed_A=high[\"OS\"], event_observed_B=low[\"OS\"]\n",
    "        )\n",
    "        p_val = lr_res.p_value\n",
    "        logrank_ps.append(p_val)\n",
    "        ax.set_title(f\"{model_name}\\nLog-Rank p = {logrank_ps[iteration]:.2e}\", fontsize=16)\n",
    "        iteration += 1\n",
    "        # KM curves\n",
    "        kmf = KaplanMeierFitter()\n",
    "        for cls in [0, 1]:\n",
    "            mask = pooled_df[\"pred_class\"] == cls\n",
    "            n_value = mask.sum()\n",
    "            kmf.fit(\n",
    "                durations=pooled_df.loc[mask, \"OS.time\"] / 365,\n",
    "                event_observed=pooled_df.loc[mask, \"OS\"],\n",
    "                label=f\"{risk_labels[cls]} (n={n_value})\"\n",
    "            )\n",
    "            kmf.plot_survival_function(ax=ax, ci_show=True, color=colours[cls])\n",
    "\n",
    "        ax.set_xlim(0, max_years)\n",
    "        ax.set_xlabel(\"Time (years)\", fontsize=16)\n",
    "        ax.set_ylabel(\"Survival probability\", fontsize=16)\n",
    "        ax.tick_params(axis=\"both\", labelsize=14)\n",
    "        ax.legend(fontsize=10,loc=\"lower left\",edgecolor=\"black\")\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for j in range(idx + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_km_curves(survival_results,max_years=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468159a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forest(survival_results, metrics_results):\n",
    "    \"\"\"\n",
    "    Plot Concordance (left) | HR (forest) (middle) | metrics table (right).\n",
    "    Model names appear on the leftmost axis (concordance). Continuous separators\n",
    "    span the full figure so lines meet across panels.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    model_list_local = list(survival_results.keys())\n",
    "\n",
    "    # Fit Cox model per model and collect HR / CI / p and c-index (assumes cph.concordance_index_ set)\n",
    "    for model_name in model_list_local:\n",
    "        dfs = []\n",
    "        for OS_val, probs_dict in survival_results[model_name]:\n",
    "            temp = OS_val.copy()\n",
    "            temp[\"score\"] = probs_dict[\"score\"]\n",
    "            dfs.append(temp)\n",
    "        pooled_df = pd.concat(dfs, ignore_index=True).dropna()\n",
    "\n",
    "        cph_df = pooled_df.rename(columns={\"OS.time\": \"time\", \"OS\": \"event\"})\n",
    "        cph = CoxPHFitter(penalizer=0.05, l1_ratio=0.0)\n",
    "        cph.fit(cph_df, duration_col=\"time\", event_col=\"event\", robust=True)\n",
    "        summary = cph.summary.loc[\"score\"]\n",
    "\n",
    "        c_index = getattr(cph, \"concordance_index_\", None)\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'HR': summary['exp(coef)'],\n",
    "            'CI_lower': summary['exp(coef) lower 95%'],\n",
    "            'CI_upper': summary['exp(coef) upper 95%'],\n",
    "            'p': summary['p'],\n",
    "            'cindex': c_index\n",
    "        })\n",
    "\n",
    "    sig_df = pd.DataFrame(results)\n",
    "\n",
    "    # Build metrics table\n",
    "    rows = []\n",
    "    for model_name in model_list_local:\n",
    "        row = {'Model': model_name}\n",
    "        ms = metrics_results.get(model_name, {})\n",
    "        if ms:\n",
    "            def to_tuple(x):\n",
    "                return x if isinstance(x, (list, tuple, np.ndarray)) else (x, np.nan)\n",
    "            row.update({\n",
    "                'accuracy_mean': to_tuple(ms.get('accuracy', (np.nan, np.nan)))[0],\n",
    "                'accuracy_std' : to_tuple(ms.get('accuracy', (np.nan, np.nan)))[1],\n",
    "                'precision_mean': to_tuple(ms.get('precision', (np.nan, np.nan)))[0],\n",
    "                'precision_std' : to_tuple(ms.get('precision', (np.nan, np.nan)))[1],\n",
    "                'recall_mean': to_tuple(ms.get('recall', (np.nan, np.nan)))[0],\n",
    "                'recall_std' : to_tuple(ms.get('recall', (np.nan, np.nan)))[1],\n",
    "                'f1_mean': to_tuple(ms.get('f1', (np.nan, np.nan)))[0],\n",
    "                'f1_std' : to_tuple(ms.get('f1', (np.nan, np.nan)))[1],\n",
    "                'roc_auc_mean': to_tuple(ms.get('roc_auc', (np.nan, np.nan)))[0],\n",
    "                'roc_auc_std' : to_tuple(ms.get('roc_auc', (np.nan, np.nan)))[1],\n",
    "                'pr_auc_mean': to_tuple(ms.get('pr_auc', (np.nan, np.nan)))[0],\n",
    "                'pr_auc_std' : to_tuple(ms.get('pr_auc', (np.nan, np.nan)))[1],\n",
    "            })\n",
    "        rows.append(row)\n",
    "    metrics_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Merge and compute significance\n",
    "    sig_df = pd.merge(sig_df, metrics_df, on=\"Model\", how=\"left\")\n",
    "    sig_df[\"Sig\"] = sig_df[\"p\"] < 0.05\n",
    "    # Keep original order\n",
    "    ordered_models = [m for m in model_list_local if m in sig_df[\"Model\"].values]\n",
    "    df_forest = sig_df.set_index(\"Model\").loc[ordered_models].reset_index()\n",
    "\n",
    "    # y positions\n",
    "    n_models = len(df_forest)\n",
    "    y = np.arange(n_models)\n",
    "\n",
    "    # Figure & GridSpec (left: concordance, mid: HR, right: table)\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    gs = gridspec.GridSpec(1, 3, width_ratios=[1.0, 1.0, 3.0], wspace=0.075)\n",
    "\n",
    "    # Create axes in the new order: concordance left, HR middle, table right\n",
    "    ax_cindex = fig.add_subplot(gs[0])\n",
    "    ax_hr = fig.add_subplot(gs[1])\n",
    "    ax_table = fig.add_subplot(gs[2])\n",
    "    ax_table.set_axis_off()\n",
    "\n",
    "    # ---------- Concordance (left) ----------\n",
    "    ax_cindex.barh(y, df_forest[\"cindex\"], align='center', height=0.6, zorder=2,\n",
    "                   edgecolor=\"black\", color=\"#7FC97F\")\n",
    "    ax_cindex.set_xlim(0, 1)\n",
    "    ax_cindex.set_xlabel(\"C-index\", fontsize=12)\n",
    "    ax_cindex.set_xticks(ticks=[0.0,0.2,0.4,0.6,0.8,1.0])\n",
    "    # put model names on the LEFT axis (concordance)\n",
    "    ax_cindex.set_yticks(y)\n",
    "    ax_cindex.set_yticklabels(df_forest[\"Model\"].tolist(), fontsize=11)\n",
    "    ax_cindex.yaxis.set_ticks_position('left')\n",
    "    ax_cindex.yaxis.set_label_position('left')\n",
    "    ax_cindex.tick_params(axis='y', labelleft=True)\n",
    "    ax_cindex.invert_yaxis()\n",
    "    ax_cindex.set_title(\"Concordance\", fontsize=12, fontweight='bold')\n",
    "    ax_cindex.tick_params(axis='x', labelsize=10)\n",
    "\n",
    "    for yi, cval in zip(y, df_forest[\"cindex\"]):\n",
    "        # annotate c-index values to the right of bars\n",
    "        if not np.isnan(cval):\n",
    "            ax_cindex.text(cval + 0.01, yi, f\"{cval:.2f}\", va='center', fontsize=9)\n",
    "\n",
    "    # ---------- Hazard Ratio (forest) (middle) ----------\n",
    "    hr_err_low = df_forest[\"HR\"] - df_forest[\"CI_lower\"]\n",
    "    hr_err_high = df_forest[\"CI_upper\"] - df_forest[\"HR\"]\n",
    "    ax_hr.errorbar(df_forest[\"HR\"], y,\n",
    "                   xerr=[hr_err_low, hr_err_high],\n",
    "                   fmt='none', ecolor='black', capsize=5, elinewidth=1.5, capthick=1.5, zorder=1)\n",
    "    ax_hr.scatter(df_forest[\"HR\"], y,\n",
    "                  c=df_forest[\"Sig\"], cmap='Set2_r',\n",
    "                  linewidths=1.5, edgecolors='black', zorder=2, vmin=0, s=150)\n",
    "\n",
    "    # hide y labels on the middle HR axis (they are on the left axis)\n",
    "    ax_hr.set_yticks(y)\n",
    "    ax_hr.set_yticklabels([])\n",
    "    ax_hr.tick_params(axis='y', length=0)\n",
    "\n",
    "    # set consistent y-limits on all axes then invert for plotting order\n",
    "    ymin, ymax = -0.5, n_models - 0.5\n",
    "    ax_cindex.set_ylim(ymin, ymax)\n",
    "    ax_hr.set_ylim(ymin, ymax)\n",
    "    ax_table.set_ylim(ymin, ymax)\n",
    "    ax_cindex.invert_yaxis()\n",
    "    ax_hr.invert_yaxis()\n",
    "    ax_table.invert_yaxis()\n",
    "\n",
    "    ax_hr.axvline(1, color='red', linestyle='--')\n",
    "    hr_max = np.nanmax(df_forest[[\"CI_upper\", \"HR\"]].values) * 1.1\n",
    "    hr_xlim = max(2, hr_max)\n",
    "    ax_hr.set_xlim(0, hr_xlim)\n",
    "    ax_hr.set_xlabel(\"Hazard Ratio (HR)\", fontsize=12)\n",
    "    ax_hr.set_title(\"Forest Plot\", fontsize=14, fontweight='bold')\n",
    "    ax_hr.tick_params(axis='x', labelsize=10)\n",
    "\n",
    "    # ---------- Metrics table (text) (right) ----------\n",
    "    headers = [\"HR\", \"p\", \"ACC\", \"PRC\", \"REC\", \"F1\", \"ROC\", \"AP\"]\n",
    "    col_x = np.linspace(0, 0.7, len(headers))\n",
    "\n",
    "    # header: just above the top row (top is at y = 0 after inversion)\n",
    "    header_y = ymin - 0.05\n",
    "    for x, h in zip(col_x, headers):\n",
    "        ax_table.text(x, header_y, h, fontsize=12, fontweight=\"bold\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # metric rows aligned with y positions\n",
    "    for row_idx, row in enumerate(df_forest.itertuples(), start=0):\n",
    "        values = [\n",
    "            f\"{row.HR:.2f}\",\n",
    "            f\"{row.p:.2e}\",\n",
    "            f\"{row.accuracy_mean:.2f}\",\n",
    "            f\"{row.precision_mean:.2f}\",\n",
    "            f\"{row.recall_mean:.2f}\",\n",
    "            f\"{row.f1_mean:.2f}\",\n",
    "            f\"{row.roc_auc_mean:.2f}\",\n",
    "            f\"{row.pr_auc_mean:.2f}\"\n",
    "        ]\n",
    "        for x, val in zip(col_x, values):\n",
    "            ax_table.text(x, row_idx, val, fontsize=10, ha=\"center\", va=\"center\")\n",
    "\n",
    "    # horizontal separators for readability\n",
    "    for yi in range(0,5):\n",
    "        ax_hr.hlines(yi + 0.5, xmin=ax_hr.get_xlim()[0], xmax=ax_hr.get_xlim()[1],\n",
    "                     colors='lightgray', linestyles='--', linewidth=1, zorder=0)\n",
    "        ax_cindex.hlines(yi + 0.5, xmin=ax_cindex.get_xlim()[0], xmax=ax_cindex.get_xlim()[1],\n",
    "                         colors='lightgray', linestyles='--', linewidth=1, zorder=0)\n",
    "\n",
    "    # ---------- Continuous separators across all panels ----------\n",
    "    # Draw full-figure separators so they meet across axes\n",
    "    fig.canvas.draw()\n",
    "    x_left_fig = ax_cindex.get_position().x0\n",
    "    x_right_fig = ax_table.get_position().x1\n",
    "    for yi in range(0,5):\n",
    "        y_data = yi + 0.5\n",
    "        _, y_disp = ax_cindex.transData.transform((0, y_data))\n",
    "        _, y_fig = fig.transFigure.inverted().transform((0, y_disp))\n",
    "        line = Line2D([x_left_fig, x_right_fig], [y_fig, y_fig], transform=fig.transFigure,\n",
    "                      color='lightgray', linestyle='--', linewidth=1, zorder=0)\n",
    "        fig.add_artist(line)\n",
    "\n",
    "    # finalize\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forest(survival_results=survival_results,metrics_results=metrics_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e27fd1",
   "metadata": {},
   "source": [
    "Exporting predictions with CGGA_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(\"./CGGA_Data/CGGA_Results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a7999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_time_roc(summary_df):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    ensemble_df = summary_df[[\"y_true\",\"OS.time\",\"OS\",\"prob_Ensemble\",\"pred_Ensemble\"]].copy()\n",
    "    def time_period(x):\n",
    "        if x <= 365*1:\n",
    "            return 1\n",
    "        elif x <= 365*3:\n",
    "            return 3\n",
    "        elif x <= 365*5:\n",
    "            return 5\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    ensemble_df[\"Time_Period\"] = ensemble_df[\"OS.time\"].apply(time_period)\n",
    "\n",
    "    df_1 = ensemble_df[ensemble_df[\"Time_Period\"]==1]\n",
    "    df_3 = ensemble_df[ensemble_df[\"Time_Period\"]==3]\n",
    "    df_5 = ensemble_df[ensemble_df[\"Time_Period\"]==5]\n",
    "\n",
    "    fpr1, tpr1, _ = roc_curve(df_1['y_true'], df_1[\"prob_Ensemble\"])\n",
    "    fpr3, tpr3, _ = roc_curve(df_3['y_true'], df_3[\"prob_Ensemble\"])\n",
    "    fpr5, tpr5, _ = roc_curve(df_5['y_true'], df_5[\"prob_Ensemble\"])\n",
    "\n",
    "    auc1 = roc_auc_score(df_1['y_true'], df_1[\"prob_Ensemble\"])\n",
    "    auc3 = roc_auc_score(df_3['y_true'], df_3[\"prob_Ensemble\"])\n",
    "    auc5 = roc_auc_score(df_5['y_true'], df_5[\"prob_Ensemble\"])\n",
    "\n",
    "    plt.plot(fpr1, tpr1, label=f\"1Yr Survival (AUC={auc1:.2f})\")\n",
    "    plt.plot(fpr3, tpr3, label=f\"3Yr Survival (AUC={auc3:.2f})\")\n",
    "    plt.plot(fpr5, tpr5, label=f\"5Yr Survival (AUC={auc5:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.title(\"Ensemble ROC Over Time\", fontsize=18)\n",
    "    plt.tick_params(axis=\"both\", labelsize=14)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_time_roc(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3716d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_curve(oof_df):\n",
    "    oof_df = oof_df.dropna().copy()\n",
    "    oof_df[\"OS.years\"] = oof_df[\"OS.time\"]/365\n",
    "    oof_df[[\"prob_Ensemble\"]] = MinMaxScaler().fit_transform(oof_df[[\"prob_Ensemble\"]])\n",
    "    model_prob_cols = [c for c in oof_df.columns if c.startswith(\"prob_\")]\n",
    "    df_dca = dca(data=oof_df,outcome='OS',modelnames=model_prob_cols, thresholds=np.arange(0,0.80,0.01),time_to_outcome_col='OS.years',time=5)\n",
    "    models_in_plot = [m for m in df_dca[\"model\"].unique()]\n",
    "    tab10 = plt.get_cmap(\"tab10\")\n",
    "    palette = [tab10(i % 10) for i in range(len(models_in_plot))]\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plot_graphs(plot_df=df_dca, graph_type='net_benefit',y_limits=[-0.05,0.5],color_names=palette,linewidths=[2],linestyles=['-','-','-','-','-','-',':','--'])\n",
    "    plt.xlabel(\"Threshold Probability\",fontsize=16)\n",
    "    # plt.yticks(ticks=[0.0,0.1,0.2,0.3,0.4],labels=[0.0,0.1,0.2,0.3,0.4])\n",
    "    plt.ylabel(\"Net Benefit\",fontsize=16)\n",
    "    plt.tick_params(axis=\"both\", labelsize=14)\n",
    "    plt.grid(visible=False)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_decision_curve(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
