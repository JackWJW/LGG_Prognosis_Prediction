{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2a97fc",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef9c71",
   "metadata": {},
   "source": [
    "Improting Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0359ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, average_precision_score, roc_curve, precision_recall_curve)\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbd16188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478cb79",
   "metadata": {},
   "source": [
    "Defining Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88c1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Binary focal loss for logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=5, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        targets = targets.view(-1, 1).type_as(logits)  # Make sure targets are (batch, 1) and same type as logits\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, reduction='none'\n",
    "        )\n",
    "\n",
    "        # Compute pt\n",
    "        pt = torch.exp(-bce_loss)\n",
    "\n",
    "        # Apply focal term\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11499a7c",
   "metadata": {},
   "source": [
    "Defining Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d03ee47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepBinary(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep feedforward model for binary classification (outputs logits).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=4, dropout_rate=0.25):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            in_dim = hidden_dim\n",
    "\n",
    "        # Final output layer â€” raw logits (no sigmoid here!)\n",
    "        layers.append(nn.Linear(hidden_dim, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # raw logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1fb16f",
   "metadata": {},
   "source": [
    "Neural Net Binary Classifier for Skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451bf352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetBinaryClassifier(NeuralNetClassifier):\n",
    "    \"\"\"\n",
    "    Skorch-compatible wrapper for binary classification that ensures predict_proba works.\n",
    "    \"\"\"\n",
    "    def predict_proba(self, X):\n",
    "        # Get logits\n",
    "        logits = self.forward(X).detach().cpu().numpy()\n",
    "        # Apply sigmoid for probabilities\n",
    "        probs = expit(logits)\n",
    "        # Return shape (n_samples, 2) for sklearn compatibility\n",
    "        return np.hstack((1 - probs, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d356f4",
   "metadata": {},
   "source": [
    "Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1f01635",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    f\"https://raw.githubusercontent.com/JackWJW/LGG_Prognosis_Prediction/main/Tidied_Datasets/tidied_integrated_df_13.csv\"\n",
    ").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "dss_info = data[[\"DSS\", \"DSS.time\"]]\n",
    "\n",
    "X = data.drop(columns=[\"Srv\", \"DSS\", \"DSS.time\"])\n",
    "y = LabelEncoder().fit_transform(data[\"Srv\"])\n",
    "\n",
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e5887",
   "metadata": {},
   "source": [
    "Defining Model Search Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6845b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "    \"SVM\": (\n",
    "        SVC(probability=True, class_weight=\"balanced\", kernel = 'rbf', gamma='scale', random_state=42),\n",
    "        {\n",
    "            \"C\": Real(0.01, 0.1)\n",
    "        }\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": Integer(50, 500),\n",
    "            \"max_depth\": Integer(2, 20),\n",
    "            \"min_samples_split\": Integer(2, 20)\n",
    "        }\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(eval_metric=\"logloss\", random_state=42),\n",
    "        {\n",
    "            \"n_estimators\": Integer(50, 500),\n",
    "            \"max_depth\": Integer(2, 10),\n",
    "            \"learning_rate\": Real(0.01, 0.3, prior=\"log-uniform\"),\n",
    "            \"subsample\": Real(0.5, 1.0)\n",
    "        }\n",
    "    ),\n",
    "    \"LogisticRegression\": (\n",
    "        LogisticRegression(max_iter=5000, class_weight=\"balanced\", solver=\"lbfgs\"),\n",
    "        {\n",
    "            \"C\": Real(0.01, 100, prior=\"log-uniform\")\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    module=DeepBinary,\n",
    "    module__input_dim=X_train.shape[1],\n",
    "    criterion=FocalLoss,\n",
    "    criterion__alpha=0.25,\n",
    "    criterion__gamma=2.0,\n",
    "    max_epochs=300,\n",
    "    lr=1e-3,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    batch_size=128,\n",
    "    iterator_train__shuffle=True,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "deep_search_space = {\n",
    "    \"lr\": Real(1e-4, 1e-1, prior=\"log-uniform\"),\n",
    "    \"module__hidden_dim\": Integer(16, 1024),\n",
    "    \"module__num_layers\": Integer(2, 8),\n",
    "    \"module__dropout_rate\": Real(0.0, 0.75),\n",
    "    \"criterion__alpha\": Real(0.0, 0.5),\n",
    "    \"criterion__gamma\": Real(2.0, 5.0)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8384776",
   "metadata": {},
   "source": [
    "Performing Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "484408d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Optimizing SVM...\n",
      "\n",
      " Optimizing RandomForest...\n",
      "\n",
      " Optimizing XGBoost...\n",
      "\n",
      " Optimizing LogisticRegression...\n",
      "\n",
      " Optimizing Deep Learning model...\n"
     ]
    }
   ],
   "source": [
    "best_params_df = pd.DataFrame()\n",
    "trained_models = {}\n",
    "val_probs = {}\n",
    "\n",
    "for model_name, (model, space) in search_spaces.items():\n",
    "    print(f\"\\n Optimizing {model_name}...\")\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"clf\", model)\n",
    "    ])\n",
    "\n",
    "    space_prefixed = {f\"clf__{k}\": v for k, v in space.items()}\n",
    "\n",
    "    opt = BayesSearchCV(\n",
    "        pipe,\n",
    "        space_prefixed,\n",
    "        n_iter=100,\n",
    "        cv=5,\n",
    "        scoring='average_precision',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        optimizer_kwargs={'n_initial_points':25}\n",
    "    )\n",
    "    opt.fit(X_train, y_train)\n",
    "    trained_models[model_name] = opt.best_estimator_\n",
    "    best_params_df = pd.concat([best_params_df, pd.DataFrame([{\"Model\": model_name, **opt.best_params_}])])\n",
    "\n",
    "print(\"\\n Optimizing Deep Learning model...\")\n",
    "\n",
    "pipe_net = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", net)\n",
    "])\n",
    "\n",
    "deep_search_space_prefixed = {f\"clf__{k}\": v for k,v in deep_search_space.items()}\n",
    "\n",
    "deep_opt = BayesSearchCV(\n",
    "    pipe_net,\n",
    "    deep_search_space_prefixed,\n",
    "    n_iter=300,\n",
    "    cv=5,\n",
    "    scoring='average_precision',\n",
    "    n_jobs=1,\n",
    "    random_state=42,\n",
    "    optimizer_kwargs={'n_initial_points':100}\n",
    ")\n",
    "deep_opt.fit(X_train.astype(np.float32), y_train)\n",
    "trained_models[\"ANN\"] = deep_opt.best_estimator_\n",
    "best_params_df = pd.concat([best_params_df, pd.DataFrame([{\"Model\": \"ANN\", **deep_opt.best_params_}])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a9cef4",
   "metadata": {},
   "source": [
    "Generating Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db44868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_list = list(val_probs.keys())\n",
    "val_probs_df = pd.DataFrame({m: val_probs[m] for m in model_names_list})\n",
    "\n",
    "# Calculate mean ensemble\n",
    "ensemble_mean = val_probs_df.mean(axis=1)\n",
    "val_probs[\"Ensemble (Mean)\"] = ensemble_mean\n",
    "\n",
    "# Calculate max ensemble\n",
    "ensemble_max = val_probs_df.max(axis=1)\n",
    "val_probs[\"Ensemble (Max)\"] = ensemble_max\n",
    "\n",
    "# Final DataFrame with everything\n",
    "val_probs_df_full = pd.DataFrame(val_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e48a16",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "011971ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>clf__C</th>\n",
       "      <th>clf__max_depth</th>\n",
       "      <th>clf__min_samples_split</th>\n",
       "      <th>clf__n_estimators</th>\n",
       "      <th>clf__learning_rate</th>\n",
       "      <th>clf__subsample</th>\n",
       "      <th>clf__criterion__alpha</th>\n",
       "      <th>clf__criterion__gamma</th>\n",
       "      <th>clf__lr</th>\n",
       "      <th>clf__module__dropout_rate</th>\n",
       "      <th>clf__module__hidden_dim</th>\n",
       "      <th>clf__module__num_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.097684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.042842</td>\n",
       "      <td>0.710585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.34829</td>\n",
       "      <td>2.084586</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.75</td>\n",
       "      <td>165.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    clf__C  clf__max_depth  clf__min_samples_split  \\\n",
       "0                 SVM  0.097684             NaN                     NaN   \n",
       "0        RandomForest       NaN            16.0                    18.0   \n",
       "0             XGBoost       NaN            10.0                     NaN   \n",
       "0  LogisticRegression  0.010000             NaN                     NaN   \n",
       "0                 ANN       NaN             NaN                     NaN   \n",
       "\n",
       "   clf__n_estimators  clf__learning_rate  clf__subsample  \\\n",
       "0                NaN                 NaN             NaN   \n",
       "0               50.0                 NaN             NaN   \n",
       "0               50.0            0.042842        0.710585   \n",
       "0                NaN                 NaN             NaN   \n",
       "0                NaN                 NaN             NaN   \n",
       "\n",
       "   clf__criterion__alpha  clf__criterion__gamma   clf__lr  \\\n",
       "0                    NaN                    NaN       NaN   \n",
       "0                    NaN                    NaN       NaN   \n",
       "0                    NaN                    NaN       NaN   \n",
       "0                    NaN                    NaN       NaN   \n",
       "0                0.34829               2.084586  0.000219   \n",
       "\n",
       "   clf__module__dropout_rate  clf__module__hidden_dim  clf__module__num_layers  \n",
       "0                        NaN                      NaN                      NaN  \n",
       "0                        NaN                      NaN                      NaN  \n",
       "0                        NaN                      NaN                      NaN  \n",
       "0                        NaN                      NaN                      NaN  \n",
       "0                       0.75                    165.0                      4.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e91a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_df.to_csv(\"./hp_best_params.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
